# 模型縮小練習
## 方法
1. 量化 (Quantization)
   - 概念：降低權重與運算數值精度，精度通常有 FP32 -> FP16 -> INT8
   - 優點：模型可以縮小四倍、降低硬體需求
   - 缺點：會影響到數值範圍比較敏感的應用
   - 方法
       - TensorFlow Lite
       - PyTorch Quantization Toolkit
       - ONNX Runtime Quantization
2. 剪枝 (Pruning)
    - 概念：刪除權重中接近 0 的參數，使模型變小、減少計算
    - 優點：模型縮小、減少參數、減少運算量
    - 缺點
        - 剪枝後模型需重新訓練，以恢復精度
        - 無法重新訓練時，剪枝效果有限
        - (NTK)對 CNN / RNN 類型的模型較適用，對 Transformer 類型影響較小
    - 方法
        - L1 / L2 剪枝（基於權重大小移除小權重）
        - 結構化剪枝（移除整個神經元 / 通道）
        - 非結構化剪枝（移除獨立權重）
        - TensorFlow Model Optimization Toolkit（TF-MOT）
        - PyTorch torch.nn.utils.prune 模組
3. 剪枝與量化的合併使用
    - 先進行剪枝以減少冗餘參數，再量化降低數值精度，達到更強的壓縮效果
    - 如果擁有資料可以重新訓練的話，建議先剪枝再量化，因為剪枝後的模型仍需訓練，量化則可用於最終部署

## 評估模型大小以比較壓縮效果
| 指標         | 計算方式                      |
|--------------|-------------------------------|
| 模型大小     | 總參數數量 × 每個參數的位元數 |
| 計算需求（FLOPs） | 每層運算量累加              |

## 目標要進行縮小的模型敘述
1. 目的：辨識聲音指令
    - 指令：請開門、請關門、請保持、一樓、二樓、三樓、四樓、五樓、六樓、七樓、八樓
2. 模型參數數量：4,442,458 in FP32 = 17.77MB
3. 總運算量：8,874,464 次計算